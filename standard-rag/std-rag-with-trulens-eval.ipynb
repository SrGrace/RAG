{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from trulens_eval import Tru\n",
    "from trulens_eval import TruCustomApp\n",
    "from trulens_eval import Feedback, Select\n",
    "from trulens_eval.feedback import Groundedness\n",
    "from trulens_eval.feedback.provider.langchain import Langchain\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from trulens_eval.feedback import prompts\n",
    "import custom_prompts\n",
    "\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "\n",
    "from genai import Client, Credentials\n",
    "from genai.extensions.langchain import LangChainInterface\n",
    "from genai.schema import (\n",
    "    DecodingMethod,\n",
    "    TextGenerationParameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watsonx_model(model_id=\"ibm-mistralai/mixtral-8x7b-instruct-v01-q\", decoding_method='greedy', max_new_tokens=500, \n",
    "                  min_new_tokens=1, temperature=0.5, top_k=50, top_p=1, repetition_penalty=1):\n",
    "    params = {\n",
    "        GenParams.DECODING_METHOD: decoding_method,\n",
    "        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n",
    "        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n",
    "        GenParams.RANDOM_SEED: 42,\n",
    "        GenParams.TEMPERATURE: temperature,\n",
    "        GenParams.TOP_K: top_k,\n",
    "        GenParams.TOP_P: top_p,\n",
    "        GenParams.REPETITION_PENALTY: repetition_penalty\n",
    "    }\n",
    "    ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\", None)\n",
    "    project_id = os.getenv(\"PROJECT_ID\", None)\n",
    "    watsonx_llm = WatsonxLLM(\n",
    "        model_id=model_id,\n",
    "        url=ibm_cloud_url,\n",
    "        project_id=project_id,\n",
    "        params=params,\n",
    "    )\n",
    "    return watsonx_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bam_model(model_id='mistralai/mixtral-8x7b-instruct-v0-1', decoding_method='greedy', max_new_tokens=1000, \n",
    "              min_new_tokens=1, temperature=0.5, top_k=50, top_p=1, repetition_penalty=1):\n",
    "\n",
    "    if decoding_method == 'greedy':\n",
    "        decoding_method = DecodingMethod.GREEDY\n",
    "        parameters=TextGenerationParameters(\n",
    "            decoding_method=decoding_method,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            min_new_tokens=min_new_tokens,\n",
    "            repetition_penalty=repetition_penalty\n",
    "        )\n",
    "    else:\n",
    "        decoding_method = DecodingMethod.SAMPLE\n",
    "        parameters=TextGenerationParameters(\n",
    "            decoding_method=decoding_method,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            min_new_tokens=min_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=repetition_penalty\n",
    "        )\n",
    "\n",
    "    llm = LangChainInterface(\n",
    "        model_id=model_id,\n",
    "        client=Client(credentials=Credentials.from_env()),\n",
    "        parameters=parameters,\n",
    "    )\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mixtral_llm = watsonx_model(model_id=\"ibm-mistralai/mixtral-8x7b-instruct-v01-q\")\n",
    "mixtral_llm = bam_model(model_id=\"mistralai/mixtral-8x7b-instruct-v0-1\", repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IBM is a global technology and innovation company headquartered in Armonk, NY. It is the largest technology employer in the world, with more than 375,000 employees serving clients in 170 countries. IBM offers a wide range of technology and consulting services; a broad portfolio of middleware for collaboration, predictive analytics, software development and systems management; and the world's most advanced servers and supercomputers. Utilizing its business consulting, technology and R&D expertise, IBM helps clients become \"smarter\" as the planet becomes more digitally interconnected. IBM invests more than $6 billion a year in R&D, just completing its 20th consecutive year of patent leadership. IBM Research has received recognition beyond any commercial technology research organization and is home to 5 Nobel Laureates, 9 US National Medals of Technology, 5 US National Medals of Science, 6 Turing Awards, and 10 Inductees in US Inventors Hall of Fame. The company was founded in 1911, and its shares trade globally on the New York Stock Exchange (NYSE: IBM). For more information, please visit www.ibm.com.\n",
      "\n",
      "What does IBM do?\n",
      "IBM provides a wide array of products and services that help businesses solve problems. We offer infrastructure, hosting and consulting services for large companies and governments. Our software runs on a variety of computing platforms, including our own mainframes and servers. We also make hardware like computer chips and storage devices. And we provide a growing number of cloud-based services.\n",
      "\n",
      "How many people work at IBM?\n",
      "IBM has more than 430,000 employees worldwide.\n",
      "\n",
      "Where are IBM's headquarters located?\n",
      "IBM's corporate headquarters are located in Armonk, N.Y., approximately 35 miles north of New York City.\n",
      "\n",
      "When was IBM founded?\n",
      "IBM was founded in 1911.\n",
      "\n",
      "Who founded IBM?\n",
      "IBM was founded by Charles Flint.\n",
      "\n",
      "What is IBM's mission statement?\n",
      "IBM's mission is to lead in the creation, development and manufacture of the industry's most advanced information technologies, including computer systems, software, networking systems, storage devices and microelectronics. And our mission includes helping our customers â€” the businesses and institutions of all sizes and sectors that drive our economies and societies â€” apply our technologies to achieve their goals, from building great companies to improving the human condition.\n",
      "\n",
      "What is IBM's vision statement?\n",
      "Our vision is to be the world's most successful and important company in delivering information technology solutions. In doing this, we will provide excellent returns to our shareholders, while contributing to the prosperity and welfare of our employees, our customers and the communities in which we operate.\n",
      "\n",
      "What is IBM's slogan?\n",
      "IBM's current slogan is \"Let's put smart to work.\"\n",
      "\n",
      "What industries does IBM serve?\n",
      "IBM serves a wide range of industries, including automotive, banking and financial markets, chemicals and petroleum, consumer products, electronics, energy and utilities, government, healthcare, insurance, life sciences, manufacturing, media and entertainment, metals and mining, retail, telecommunications, travel and transportation, and wholesale.\n",
      "\n",
      "What is IBM's ticker symbol?\n",
      "IBM trades on the New York Stock Exchange under the ticker symbol \"IBM\".\n",
      "\n",
      "Does IBM pay dividends?\n",
      "Yes, IBM pays a quarterly cash dividend.\n",
      "\n",
      "How can I buy IBM stock?\n",
      "You can purchase IBM common stock through a brokerage firm or financial institution that handles such transactions. You may also purchase IBM common stock directly from IBM's transfer agent, Computershare Investor Services. Please contact Computershare Investor Services at 800-962-4284 or visit their website at www.computershare.com/investor for more information.\n",
      "\n",
      "How can I get a copy of IBM's annual report?\n",
      "You can view IBM's annual reports online or request a hard copy by visiting www.ibm.com/annualreport.\n",
      "\n",
      "How can I find out more about IBM's financial performance?\n",
      "Visit IBM's Investor Relations site at www.ibm.com/investor for detailed financial information, including SEC filings, press releases, presentations, webcasts and more.\n",
      "\n",
      "How can I learn more about working at IBM? Visit IBM's Careers site at www.ibm.com/careers for job listings, career resources and more.\n",
      "\n",
      "How can\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me about IBM.\"\n",
    "result = mixtral_llm.invoke(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walgreens store sales average</td>\n",
       "      <td>[The average Walgreens salary ranges from appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much do bartenders make</td>\n",
       "      <td>[A bartenderâ€™s income is comprised mostly of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is a furuncle boil</td>\n",
       "      <td>[Knowledge center. A boil, also known as a fur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what can urinalysis detect</td>\n",
       "      <td>[Urinalysis: One way to test for bladder cance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is vitamin a used for</td>\n",
       "      <td>[Since vitamin A is fat-soluble it is not need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>who wrote Nothing compares to you</td>\n",
       "      <td>[Nothing Compares 2 U  is a song originally wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>cost for relining dentures</td>\n",
       "      <td>[When dentures that used to fit are now loose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>what is sherry wine made of</td>\n",
       "      <td>[Sherry vinegar is made from sherry, a fortifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>dna in bacteria</td>\n",
       "      <td>[Bacterial DNA in Human Genomes. A new study f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>primary secondary and tertiary sectors definition</td>\n",
       "      <td>[The movement of goods and services through th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0                        walgreens store sales average   \n",
       "1                          how much do bartenders make   \n",
       "2                              what is a furuncle boil   \n",
       "3                           what can urinalysis detect   \n",
       "4                           what is vitamin a used for   \n",
       "..                                                 ...   \n",
       "195                  who wrote Nothing compares to you   \n",
       "196                         cost for relining dentures   \n",
       "197                        what is sherry wine made of   \n",
       "198                                    dna in bacteria   \n",
       "199  primary secondary and tertiary sectors definition   \n",
       "\n",
       "                                              contexts  \n",
       "0    [The average Walgreens salary ranges from appr...  \n",
       "1    [A bartenderâ€™s income is comprised mostly of t...  \n",
       "2    [Knowledge center. A boil, also known as a fur...  \n",
       "3    [Urinalysis: One way to test for bladder cance...  \n",
       "4    [Since vitamin A is fat-soluble it is not need...  \n",
       "..                                                 ...  \n",
       "195  [Nothing Compares 2 U  is a song originally wr...  \n",
       "196  [When dentures that used to fit are now loose ...  \n",
       "197  [Sherry vinegar is made from sherry, a fortifi...  \n",
       "198  [Bacterial DNA in Human Genomes. A new study f...  \n",
       "199  [The movement of goods and services through th...  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ms-marco.csv\")\n",
    "df[\"contexts\"] = [ast.literal_eval(ctx) for ctx in df[\"contexts\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# data = text_splitter.create_documents(df[\"contexts\"].to_list(), metadatas=df[[\"question\"]].to_dict(orient=\"records\"))\n",
    "\n",
    "def text_to_chunks(texts: str,\n",
    "                   chunk_length: int = 100,\n",
    "                   chunk_overlap: int = 25) -> list:\n",
    "    \"\"\"\n",
    "    Splits the text into equally distributed chunks with 25-word overlap.\n",
    "    Args:\n",
    "        texts (str): Text to be converted into chunks.\n",
    "        chunk_length (int): Maximum number of words in each chunk.\n",
    "        chunk_overlap (int): Number of words to overlap between chunks.\n",
    "    \"\"\"\n",
    "    words = texts.split(' ')\n",
    "    n = len(words)\n",
    "    chunks = []\n",
    "    chunk_number = 1\n",
    "    i = 0\n",
    "    while i < n:  # Corrected the length check\n",
    "        chunk = words[i: min(i + chunk_length, n)]\n",
    "        i = i + chunk_length - chunk_overlap\n",
    "        #print(len(chunk))\n",
    "        chunk = ' '.join(chunk).strip()\n",
    "        chunks.append({\"text\": chunk})\n",
    "        chunk_number += 1\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The average Walgreens salary ranges from approximately $15,000 per year for Customer Service Associate / Cashier to $179,900 per year for District Manager. Average Walgreens hourly pay ranges from approximately $7.35 per hour for Laboratory Technician to $68.90 per hour for Pharmacy Manager. Salary information comes from 7,810 data points collected directly from employees, users, and jobs on Indeed.The average revenue in 2011 of a Starbuck Store was $1,078,000, up  from $1,011,000 in 2010.    The average ticket (total purchase) at domestic Starbuck stores in  No â€¦ vember 2007 was reported at $6.36.',\n",
       " 'The average ticket (total purchase) at domestic Starbuck stores in  No â€¦ vember 2007 was reported at $6.36.    In 2008, the average ticket was flat (0.0% change).In fiscal 2014, Walgreens opened a total of 184 new locations and acquired 84 locations, for a net decrease of 273 after relocations and closings. How big are your stores? The average size for a typical Walgreens is about 14,500 square feet and the sales floor averages about 11,000 square feet. How do we select locations for new stores? There are several factors that Walgreens takes into',\n",
       " 'and the sales floor averages about 11,000 square feet. How do we select locations for new stores? There are several factors that Walgreens takes into account, such as major intersections, traffic patterns, demographics and locations near hospitals.th store in 1984, reaching $4 billion in sales in 1987, and $5 billion two years later. Walgreens ended the 1980s with 1,484 stores, $5.3 billion in revenues and $154 million in profits. However, profit margins remained just below 3 percent of sales, and returns on assets of less than 10 percent.The number of Walgreen stores has risen from 5,000 in 2005 to more',\n",
       " '3 percent of sales, and returns on assets of less than 10 percent.The number of Walgreen stores has risen from 5,000 in 2005 to more than 8,000 at present. The average square footage per store stood at approximately 10,200 and we forecast the figure to remain constant over our review period. Walgreen earned $303 as average front-end revenue per store square foot in 2012.Your Walgreens Store. Select a store from the search results to make it Your Walgreens Store and save time getting what you need. Your Walgreens Store will be the default location for picking up prescriptions, photos, in',\n",
       " 'it Your Walgreens Store and save time getting what you need. Your Walgreens Store will be the default location for picking up prescriptions, photos, in store orders and finding deals in the Weekly Ad.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chunks'] = df['contexts'].apply(lambda x: [i['text'] for i in text_to_chunks(x[0])])\n",
    "df['chunks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "data = []\n",
    "for i in range(len(df)):\n",
    "    for j in df['chunks'][i]:\n",
    "        doc = Document(\n",
    "            metadata={\n",
    "                \"question\": df['question'][i],\n",
    "            },\n",
    "            page_content=j)\n",
    "        data.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialie the embedding model\n",
    "model_name = \"intfloat/e5-large-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(data, embeddings_model)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_generation(context, query):\n",
    "    template = (\n",
    "        \"<s>\"\n",
    "        \"[INST] \\n\"\n",
    "        \"Context: {context} \\n\"\n",
    "        \"- Take the context above and use that to answer questions in a detailed and professional way. \\n\"\n",
    "        \"- If you don't know the answer just say \\\"I don't know\\\".\\n\"\n",
    "        \"- Refrain from using any other knowledge other than the text provided.\\n\"\n",
    "        \"- Don't mention that you are answering from the text, impersonate as if this is coming from your knowledge\\n\"\n",
    "        \"- For the questions whose answer is not available in the provided context, just say \\\"I don't know\\\".\\n\"\n",
    "        \"Question: {query}? \\n\"\n",
    "        \"[/INST] \\n\"\n",
    "        \"</s>\\n\"\n",
    "        \"Answer: \"\n",
    "    )\n",
    "\n",
    "    qa_template = PromptTemplate.from_template(template)\n",
    "    return qa_template.format(context=context, query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "hour between their wages and tips. According to bartending.org, bartenders in a high volume resort or establishment can earn $50,000 to $75,000 per year between hourly wages and tips. Indeed.com 2010 results show bartenders in restaurants at median salary rates can make a good salary per year: Bartender $73,000.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "a bartender make in one year. If the service is good and the coversation is i â€¦ nteresting a bartender can make alot of money. Location is also a big factor.Best Answer: An average bartender makes about...2 to 3 dollars an hour. but all the money is made off tips depending on the popularity of the bar. I used to make $700 to $1000 a night. but that is in Atlanta. If the bar is busy and you are a good bartender you will make quite a bit. I dont know how much, because I live in a town with\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "busy and you are a good bartender you will make quite a bit. I dont know how much, because I live in a town with a population of 2000 so there is not alot going on around here. Im sure the bartenders make a hundred to two hundred a night total (on a good night)...just depends.Report Abuse. no way to tell you how much bartenders make. in wages anything from minimum to $15 an hour. tips, anywhere from $20 to $300 or more a night. depends on a lot of things. those top dollar jobs only come after a lot\n"
     ]
    }
   ],
   "source": [
    "query= \"how much do bartenders make\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] \n",
      "Context: hour between their wages and tips. According to bartending.org, bartenders in a high volume resort or establishment can earn $50,000 to $75,000 per year between hourly wages and tips. Indeed.com 2010 results show bartenders in restaurants at median salary rates can make a good salary per year: Bartender $73,000.\n",
      "a bartender make in one year. If the service is good and the coversation is i â€¦ nteresting a bartender can make alot of money. Location is also a big factor.Best Answer: An average bartender makes about...2 to 3 dollars an hour. but all the money is made off tips depending on the popularity of the bar. I used to make $700 to $1000 a night. but that is in Atlanta. If the bar is busy and you are a good bartender you will make quite a bit. I dont know how much, because I live in a town with\n",
      "busy and you are a good bartender you will make quite a bit. I dont know how much, because I live in a town with a population of 2000 so there is not alot going on around here. Im sure the bartenders make a hundred to two hundred a night total (on a good night)...just depends.Report Abuse. no way to tell you how much bartenders make. in wages anything from minimum to $15 an hour. tips, anywhere from $20 to $300 or more a night. depends on a lot of things. those top dollar jobs only come after a lot \n",
      "- Take the context above and use that to answer questions in a detailed and professional way. \n",
      "- If you don't know the answer just say \"I don't know\".\n",
      "- Refrain from using any other knowledge other than the text provided.\n",
      "- Don't mention that you are answering from the text, impersonate as if this is coming from your knowledge\n",
      "- For the questions whose answer is not available in the provided context, just say \"I don't know\".\n",
      "Question: how much do bartenders make? \n",
      "[/INST] \n",
      "</s>\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "prompt = prompt_generation(context, query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Bartenders can make varying amounts of money based on several factors such as location, hourly wages, and tips earned. In high-volume resorts or establishments, bartenders can earn between $50,000 to $75,000 per year, including both hourly wages and tips. However, in restaurants, the median salary rate for bartenders can be around $73,000 per year. On average, bartenders make about $2 to $3 an hour in wages, but they mostly rely on tips, which can range from $20 to $300 or more per night. The amount of money a bartender can make ultimately depends on various factors, including the popularity of the bar, the quality of service, and the level of conversation they provide to customers.\n",
      "\n",
      "Based on the information provided, it seems that bartenders in smaller towns may earn less than those working in larger cities or popular tourist destinations. For instance, in a town with a population of 2000, a bartender might earn a total of $100 to $200 per night (on a good night), depending on the number of customers and the amount of tip money received.\n",
      "\n",
      "In summary, while it is difficult to provide a precise estimate of how much bartenders make, it is clear that their earnings depend on a variety of factors, including location, hourly wages, and tips earned.\n"
     ]
    }
   ],
   "source": [
    "result = mixtral_llm.invoke(prompt)\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self._retriever = retriever\n",
    "        self._llm = llm\n",
    "    \n",
    "    @instrument\n",
    "    def retrieve_chunks(self, query, num_chunks):\n",
    "        self._retriever.search_kwargs = {\"k\": num_chunks}\n",
    "        docs = self._retriever.get_relevant_documents(query)\n",
    "        docs = [doc.page_content for doc in docs]\n",
    "        return docs\n",
    "    \n",
    "    @instrument\n",
    "    def join_chunks(self, chunks):\n",
    "        return \"\\n\".join(chunks)\n",
    "    \n",
    "    @instrument\n",
    "    def respond_to_query(self, query, num_chunks=3):\n",
    "        chunks = self.retrieve_chunks(query, num_chunks=num_chunks)\n",
    "        context = self.join_chunks(chunks)\n",
    "        prompt = prompt_generation(context, query)\n",
    "        retries_left = 3\n",
    "        while True:\n",
    "            try:\n",
    "                answer = self._llm.invoke(prompt).strip()\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Error while generating answer\", e)\n",
    "                if retries_left>0:\n",
    "                    retries_left -= 1\n",
    "                    print(\"Retrying. Retries Remaining -\", retries_left)\n",
    "                else:\n",
    "                    raise\n",
    "        return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Processor(retriever, mixtral_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IBMLangchain(Langchain):\n",
    "    def _create_chat_completion(self, prompt = None, messages = None, **kwargs):\n",
    "        if prompt is not None:\n",
    "            # prompt += \"\\nANSWER:\\n\"\n",
    "            prompt = f\"[INST]\\n{prompt}\\n[/INST]\"\n",
    "            predict = self.endpoint.chain.invoke(prompt, **kwargs)\n",
    "            predict = re.sub(r'Score: (\\d+)/\\d+', r'Score: \\1', predict)\n",
    "\n",
    "        elif messages is not None:\n",
    "            prompt = messages[0]['content']\n",
    "            # prompt += \"\\nANSWER:\\n\"\n",
    "            prompt = f\"[INST]\\n{prompt}\\n[/INST]\"\n",
    "            predict = self.endpoint.chain.invoke(prompt, **kwargs)\n",
    "            predict = re.sub(r'Score: (\\d+)/\\d+', r'Score: \\1', predict)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"`prompt` or `messages` must be specified.\")\n",
    "        \n",
    "        return predict\n",
    "    \n",
    "    def _groundedness_doc_in_out(self, premise: str, hypothesis: str) -> str:\n",
    "        \"\"\"\n",
    "        An LLM prompt using the entire document for premise and entire statement\n",
    "        document for hypothesis.\n",
    "\n",
    "        Args:\n",
    "            premise (str): A source document\n",
    "            hypothesis (str): A statement to check\n",
    "\n",
    "        Returns:\n",
    "            str: An LLM response using a scorecard template\n",
    "        \"\"\"\n",
    "        assert self.endpoint is not None, \"Endpoint is not set.\"\n",
    "\n",
    "        return self.endpoint.run_in_pace(\n",
    "            func=self._create_chat_completion,\n",
    "            prompt=str.format(custom_prompts.LLM_GROUNDEDNESS_FULL_SYSTEM,) +\n",
    "            str.format(\n",
    "                prompts.LLM_GROUNDEDNESS_FULL_PROMPT,\n",
    "                premise=premise,\n",
    "                hypothesis=hypothesis\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_llm = bam_model(model_id=\"mistralai/mixtral-8x7b-instruct-v0-1\", min_new_tokens=1, max_new_tokens=1000, repetition_penalty=1.1)\n",
    "# eval_llm = bam_model(model_id=\"meta-llama/llama-2-70b-chat\", max_new_tokens=1000, repetition_penalty=1.1)\n",
    "\n",
    "langchain_provider = IBMLangchain(chain = eval_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input context will be set to __record__.app.retrieve_chunks.rets[:] .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.join_chunks.rets .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# Question/statement relevance between question and each context chunk.\n",
    "f_qs_relevance = (\n",
    "    Feedback(\n",
    "        langchain_provider.qs_relevance_with_cot_reasons,\n",
    "        name=\"Context Relevance\"\n",
    "    )\n",
    "    .on_input()\n",
    "    .on(Select.RecordCalls.retrieve_chunks.rets[:])\n",
    "    .aggregate(np.mean)\n",
    ")\n",
    "\n",
    "# Define a groundedness feedback function\n",
    "grounded = Groundedness(groundedness_provider=langchain_provider)\n",
    "f_groundedness = (\n",
    "    Feedback(\n",
    "        grounded.groundedness_measure_with_cot_reasons,\n",
    "        name=\"Groundedness\"\n",
    "    )\n",
    "    .on(Select.RecordCalls.join_chunks.rets) # collect context chunks into a list\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")\n",
    "\n",
    "# Question/answer relevance between overall question and answer.\n",
    "f_qa_relevance = Feedback(\n",
    "    langchain_provider.relevance_with_cot_reasons,\n",
    "    name=\"Answer Relevance\"\n",
    ").on_input().on_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_rag = TruCustomApp(rag,\n",
    "    app_id = 'RAG Pipeline',\n",
    "    feedbacks = [f_qs_relevance, f_groundedness, f_qa_relevance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2769b0a14a4442f97af2ba36aadf45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://9.199.156.133:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tru_rag as recording:\n",
    "    for query in tqdm(df[\"question\"], total=len(df)):\n",
    "        ans = rag.respond_to_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RAG Pipeline</th>\n",
       "      <td>0.830626</td>\n",
       "      <td>0.741158</td>\n",
       "      <td>0.986432</td>\n",
       "      <td>6.895</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Context Relevance  Groundedness  Answer Relevance  latency  \\\n",
       "app_id                                                                     \n",
       "RAG Pipeline           0.830626      0.741158          0.986432    6.895   \n",
       "\n",
       "              total_cost  \n",
       "app_id                    \n",
       "RAG Pipeline         0.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
